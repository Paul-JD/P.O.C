{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:58:38.615033100Z",
     "start_time": "2023-08-31T22:58:37.829157700Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "from collections import Counter\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "url = \"https://files.data.gouv.fr/geo-dvf/latest/csv/2018/full.csv.gz\"\n",
    "req = requests.get(url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:58:44.051470Z",
     "start_time": "2023-08-31T22:58:38.604020400Z"
    }
   },
   "id": "2ee85954a7585345"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "t = req.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:58:44.093011900Z",
     "start_time": "2023-08-31T22:58:44.052478400Z"
    }
   },
   "id": "a0f8f2266c261484"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "s = gzip.decompress(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:58:47.472420100Z",
     "start_time": "2023-08-31T22:58:44.065478300Z"
    }
   },
   "id": "ed9fea5b0affa2d1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dargo\\AppData\\Local\\Temp\\ipykernel_3840\\798997524.py:1: DtypeWarning: Columns (8,10,12,14,16,17,18,20,22,26,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(io.BytesIO(s))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(io.BytesIO(s))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:02.331602300Z",
     "start_time": "2023-08-31T22:58:47.473420100Z"
    }
   },
   "id": "932b5e490983f2cc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# suppression valeur fonciere nulle\n",
    "df.dropna(subset=['valeur_fonciere'], inplace=True)\n",
    "df.dropna(subset=['longitude', 'latitude'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:04.974785800Z",
     "start_time": "2023-08-31T22:59:02.335607500Z"
    }
   },
   "id": "8a4eef8c0ec9fe2c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Selection des colonnes utiles\n",
    "dataset = df[['id_mutation',\n",
    "              'date_mutation',\n",
    "              'nature_mutation',\n",
    "              'adresse_nom_voie',\n",
    "              'code_postal',\n",
    "              'code_commune',\n",
    "              'code_departement',\n",
    "              'nombre_lots',\n",
    "              'type_local',\n",
    "              'surface_reelle_bati',\n",
    "              'nombre_pieces_principales',\n",
    "              'code_nature_culture',\n",
    "              'code_nature_culture_speciale',\n",
    "              'surface_terrain',\n",
    "              'valeur_fonciere',\n",
    "              'longitude',\n",
    "              'latitude'\n",
    "              ]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:05.355815300Z",
     "start_time": "2023-08-31T22:59:04.978827200Z"
    }
   },
   "id": "e56e372dae07f21d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "del df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:05.748527Z",
     "start_time": "2023-08-31T22:59:05.356817500Z"
    }
   },
   "id": "b5c88c697d2a8201"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8c6572facca896a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3201638, 17)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:05.824251900Z",
     "start_time": "2023-08-31T22:59:05.751579800Z"
    }
   },
   "id": "fe6ac2634226c233"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Date mutation cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da7ef45987f3d39"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Passage de la colonnes date mutation en datetime puis en seconde pour avoir des int\n",
    "dataset.loc[:, 'date_mutation'] = pd.to_datetime(dataset['date_mutation'], format='mixed')\n",
    "dataset.loc[:, 'date_mutation'] = dataset['date_mutation'].apply(lambda x: x.timestamp())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:16.128184100Z",
     "start_time": "2023-08-31T22:59:05.783526700Z"
    }
   },
   "id": "410b6bd7489f0c65"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Remplissage des valeurs NaN nature_mutation et labelisation\n",
    "dataset.loc[:, 'nature_mutation'] = dataset.nature_mutation.fillna(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:16.351105300Z",
     "start_time": "2023-08-31T22:59:16.131223100Z"
    }
   },
   "id": "55ea0df08ab8429f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NM = preprocessing.LabelEncoder()\n",
    "NM.fit(dataset['nature_mutation'])\n",
    "dataset.loc[:, 'nature_mutation'] = NM.transform(dataset['nature_mutation'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bbe127e6e9d3727"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adresse nom voie cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc749794b07b0da3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "abrv_voie = pd.read_csv(filepath_or_buffer='Data_Files/ABREVIATION_VOIE.csv', sep=',').values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:16.366106800Z",
     "start_time": "2023-08-31T22:59:16.354147600Z"
    }
   },
   "id": "8465c1c51bdec236"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dataset.loc[:, 'adresse_nom_voie'] = dataset.adresse_nom_voie.fillna(\"\")\n",
    "\n",
    "codex_voie = list()\n",
    "for i in dataset.adresse_nom_voie.values:\n",
    "\n",
    "    list_nom_rue = i.split(' ')\n",
    "    premier_valeur_liste = list_nom_rue[0]\n",
    "\n",
    "    if premier_valeur_liste in abrv_voie:\n",
    "        codex_voie.append(premier_valeur_liste)\n",
    "    else:\n",
    "        codex_voie.append('AUTRE')\n",
    "\n",
    "dataset.loc[:, 'prefixe_voie'] = codex_voie"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:39.139030300Z",
     "start_time": "2023-08-31T22:59:16.369145400Z"
    }
   },
   "id": "1109a459bcdc1b60"
  },
  {
   "cell_type": "markdown",
   "source": [
    "CV = preprocessing.LabelEncoder()\n",
    "CV.fit(dataset.prefixe_voie)\n",
    "dataset.loc[:,'prefixe_voie'] = CV.transform(dataset.prefixe_voie)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9df4c03294ab1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiple easy Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e52995de51908ce9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dataset.loc[:, 'code_postal'] = dataset.code_postal.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:39.234556700Z",
     "start_time": "2023-08-31T22:59:39.144031400Z"
    }
   },
   "id": "9a31b10f690da8e7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dataset.loc[:, 'surface_reelle_bati'] = dataset.surface_reelle_bati.fillna(0)\n",
    "dataset.loc[:, 'surface_terrain'] = dataset.surface_terrain.fillna(0)\n",
    "dataset.loc[:, 'type_local'] = dataset.type_local.fillna('Autre')\n",
    "dataset.loc[:, 'nombre_pieces_principales'] = dataset.nombre_pieces_principales.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:39.627855500Z",
     "start_time": "2023-08-31T22:59:39.236559Z"
    }
   },
   "id": "6b61f19cf0aceb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "dataset.loc[:, 'code_nature_culture'] = dataset.code_nature_culture.fillna(\"\")\n",
    "dataset.loc[:, 'code_nature_culture_speciale'] = dataset.code_nature_culture_speciale.fillna(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.036384500Z",
     "start_time": "2023-08-31T22:59:39.630897700Z"
    }
   },
   "id": "5f406383cd6b6ab1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Latitude & longitude"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8987fac75112dc2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construction data set modele"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b049722fe2a8e209"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "classe_liste_nature_mutation = list(dict.fromkeys(list(dataset.nature_mutation.values)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.161400600Z",
     "start_time": "2023-08-31T22:59:40.040384600Z"
    }
   },
   "id": "d736eb863bc08db4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "classe_liste_code_type_local = list(dict.fromkeys(list(dataset.type_local.values)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.331631800Z",
     "start_time": "2023-08-31T22:59:40.165417Z"
    }
   },
   "id": "920cd24c3eaf4b67"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "classe_liste_prefixe_voie = list(dict.fromkeys(codex_voie))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.495799Z",
     "start_time": "2023-08-31T22:59:40.313118200Z"
    }
   },
   "id": "cc7fa6d25879e980"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "classe_liste_code_culture = pd.read_csv(filepath_or_buffer='Data_Files/CODE_CULTURE.csv', sep=',')\n",
    "classe_liste_code_culture = list(classe_liste_code_culture['Code_nature_culture'].to_dict().values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.510797700Z",
     "start_time": "2023-08-31T22:59:40.483841100Z"
    }
   },
   "id": "9b0c72d63c8ef10b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "classe_liste_code_culture_spe = pd.read_csv(filepath_or_buffer='Data_Files/CODE_CULTURE_SPECIALE.csv', sep=',')\n",
    "classe_liste_code_culture_spe = list(classe_liste_code_culture_spe['CODE_CULTURE_SPECIALE'].to_dict().values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.556325800Z",
     "start_time": "2023-08-31T22:59:40.512799100Z"
    }
   },
   "id": "241ad3a1371acdaa"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "Nom_colonnes_from_dataset = [\n",
    "    'date_mutation',\n",
    "    'code_postal',\n",
    "    'code_commune',\n",
    "    'code_departement',\n",
    "    'nombre_lots',\n",
    "    'surface_reelle_bati',\n",
    "    'nombre_pieces_principales',\n",
    "    'surface_terrain',\n",
    "    'valeur_fonciere',\n",
    "    'longitude',\n",
    "    'latitude'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.556325800Z",
     "start_time": "2023-08-31T22:59:40.528807100Z"
    }
   },
   "id": "c3aa3976be10794f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "colonnes = Nom_colonnes_from_dataset + classe_liste_code_type_local + classe_liste_prefixe_voie + classe_liste_nature_mutation + classe_liste_code_culture + classe_liste_code_culture_spe\n",
    "colonnes = np.array(colonnes)\n",
    "del classe_liste_nature_mutation, classe_liste_code_type_local, classe_liste_prefixe_voie, classe_liste_code_culture, classe_liste_code_culture_spe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.560325800Z",
     "start_time": "2023-08-31T22:59:40.545325200Z"
    }
   },
   "id": "9b3dbe4c60676100"
  },
  {
   "cell_type": "markdown",
   "source": [
    "assert 1 == len(pd.unique(TEST.date_mutation))\n",
    "assert 1 == len(pd.unique(TEST.valeur_fonciere))\n",
    "assert 1 == len(pd.unique(TEST.code_postal))\n",
    "assert 1 == len(pd.unique(TEST.code_commune))\n",
    "assert 1 == len(pd.unique(TEST.code_departement))\n",
    "assert len(ajout_culture_spe) == len(classe_liste_code_culture_spe)\n",
    "assert len(ajout_culture) == len(classe_liste_code_culture)\n",
    "assert len(ajout_nature_mutation) == len(classe_liste_nature_mutation)\n",
    "assert len(ajout_abbrev_voie) == len(classe_liste_prefixe_voie)\n",
    "assert len(ajout_code_type) == len(classe_liste_code_type_local)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da16b1c1a340466"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset creation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d44b41cf16f43474"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "test = dataset.loc[0:100000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.603325Z",
     "start_time": "2023-08-31T22:59:40.560325800Z"
    }
   },
   "id": "85ca41a00a0ffa5d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "list_id_mutation = list(dict.fromkeys(test.id_mutation.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.623341400Z",
     "start_time": "2023-08-31T22:59:40.592334200Z"
    }
   },
   "id": "8b5227181774eebd"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class My_thread(Thread):\n",
    "    def __init__(self, id, dataset, colonnes):\n",
    "        super(My_thread, self).__init__()\n",
    "        self.id = id\n",
    "        self.dataset = dataset\n",
    "        self.colonnes = colonnes\n",
    "        self.retour = pd.DataFrame()\n",
    "\n",
    "    def run(self) -> None:\n",
    "        tmp_dataset = self.dataset\n",
    "        index = tmp_dataset.index[0]\n",
    "        tmp_dict = dict.fromkeys(self.colonnes)\n",
    "\n",
    "        tmp_dict['date_mutation'] = [tmp_dataset.loc[index, 'date_mutation']]\n",
    "        tmp_dict['code_postal'] = [tmp_dataset.loc[index, 'code_postal']]\n",
    "        tmp_dict['code_commune'] = [tmp_dataset.loc[index, 'code_commune']]\n",
    "        tmp_dict['code_departement'] = [tmp_dataset.loc[index, 'code_departement']]\n",
    "        tmp_dict['nombre_lots'] = [tmp_dataset.loc[index, 'nombre_lots'].sum()]\n",
    "        tmp_dict['surface_reelle_bati'] = [tmp_dataset.loc[index, 'surface_reelle_bati'].sum()]\n",
    "        tmp_dict['nombre_pieces_principales'] = [tmp_dataset.loc[index, 'nombre_pieces_principales'].sum()]\n",
    "        tmp_dict['surface_terrain'] = [tmp_dataset.loc[index, 'surface_terrain'].sum()]\n",
    "        tmp_dict['valeur_fonciere'] = [tmp_dataset.loc[index, 'valeur_fonciere']]\n",
    "        tmp_dict['longitude'] = [tmp_dataset.loc[index, 'longitude']]\n",
    "        tmp_dict['latitude'] = [tmp_dataset.loc[index, 'latitude']]\n",
    "\n",
    "        # valeur classe code type local\n",
    "        count_type_local = Counter(tmp_dataset.loc[:, 'type_local'])\n",
    "        for type_local in count_type_local:\n",
    "            tmp_dict[type_local] = count_type_local[type_local]\n",
    "\n",
    "        # valeur prefixe voie\n",
    "        count_prefixe_voie = Counter(tmp_dataset.loc[:, 'prefixe_voie'])\n",
    "        for abbrev_voie in count_prefixe_voie:\n",
    "            tmp_dict[abbrev_voie] = count_prefixe_voie[abbrev_voie]\n",
    "\n",
    "        # valeur classe nature mutation\n",
    "        count_nature_mutation = Counter(tmp_dataset.loc[:, 'nature_mutation'])\n",
    "        for nat_mutation in count_nature_mutation:\n",
    "            tmp_dict[nat_mutation] = count_nature_mutation[nat_mutation]\n",
    "\n",
    "        # valeur classe culture\n",
    "        count_type_culture = Counter(tmp_dataset.loc[:, 'code_nature_culture'])\n",
    "        for culture in count_type_culture:\n",
    "            tmp_dict[culture] = count_type_culture[culture]\n",
    "\n",
    "        # valeur classe culture\n",
    "        count_type_culture_spe = Counter(tmp_dataset.loc[:, 'code_nature_culture_speciale'])\n",
    "        for culture_spe in count_type_culture_spe:\n",
    "            tmp_dict[culture_spe] = count_type_culture_spe[culture_spe]\n",
    "\n",
    "        self.retour = pd.DataFrame.from_dict(tmp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.667930400Z",
     "start_time": "2023-08-31T22:59:40.615326200Z"
    }
   },
   "id": "65f1a24386edfc"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "th_liste = list(range(len(list_id_mutation)))\n",
    "Data = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:59:40.669928600Z",
     "start_time": "2023-08-31T22:59:40.638967800Z"
    }
   },
   "id": "e18b9f36104b42e1"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "for i, id in enumerate(list_id_mutation):\n",
    "    tmp = test.loc[test.id_mutation == id, :]\n",
    "    th_liste[i]: My_thread = My_thread(id, tmp, colonnes)\n",
    "    th_liste[i].start()\n",
    "    test = test.drop(test[test.id_mutation == id].index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T23:11:02.341160200Z",
     "start_time": "2023-08-31T22:59:40.673929500Z"
    }
   },
   "id": "b59acc42641f47f3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "list_panda = list()\n",
    "for j in range(len(list_id_mutation)):\n",
    "    th_liste[j].join()\n",
    "    list_panda.append(th_liste[j].retour)\n",
    "Data = pd.concat(list_panda, ignore_index=True, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T23:14:11.301451Z",
     "start_time": "2023-08-31T23:11:02.344175300Z"
    }
   },
   "id": "2f19eb84ff32143a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "Data = Data.fillna(0)\n",
    "Data.to_csv(path_or_buf='C:/Users/dargo/Files_clean/2018_data_set_clean.csv', sep=',', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T23:14:14.826254800Z",
     "start_time": "2023-08-31T23:14:11.308415500Z"
    }
   },
   "id": "575e5c96fd86db9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# autre methode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ea5883083b5e864"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m tmp_dataset \u001B[38;5;241m=\u001B[39m test\u001B[38;5;241m.\u001B[39mloc[dataset\u001B[38;5;241m.\u001B[39mid_mutation \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m]\n\u001B[0;32m      5\u001B[0m test \u001B[38;5;241m=\u001B[39m test\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;28mlist\u001B[39m(test\u001B[38;5;241m.\u001B[39mloc[test\u001B[38;5;241m.\u001B[39mid_mutation \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mid\u001B[39m, :]\u001B[38;5;241m.\u001B[39mindex))\n\u001B[1;32m----> 6\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[43mtmp_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      8\u001B[0m tmp_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m\u001B[38;5;241m.\u001B[39mfromkeys(colonnes)\n\u001B[0;32m     10\u001B[0m tmp_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_mutation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [tmp_dataset\u001B[38;5;241m.\u001B[39mloc[index, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate_mutation\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProjectPOC\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5365\u001B[0m, in \u001B[0;36mIndex.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   5362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(key) \u001B[38;5;129;01mor\u001B[39;00m is_float(key):\n\u001B[0;32m   5363\u001B[0m     \u001B[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001B[39;00m\n\u001B[0;32m   5364\u001B[0m     key \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mcast_scalar_indexer(key)\n\u001B[1;32m-> 5365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgetitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mslice\u001B[39m):\n\u001B[0;32m   5368\u001B[0m     \u001B[38;5;66;03m# This case is separated from the conditional above to avoid\u001B[39;00m\n\u001B[0;32m   5369\u001B[0m     \u001B[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001B[39;00m\n\u001B[0;32m   5370\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_slice(key)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "Data = pd.DataFrame()\n",
    "for i, id in enumerate(list_id_mutation):\n",
    "\n",
    "    tmp_dataset = test.loc[dataset.id_mutation == id]\n",
    "    test = test.drop(list(test.loc[test.id_mutation == id, :].index))\n",
    "    index = tmp_dataset.index[0]\n",
    "\n",
    "    tmp_dict = dict.fromkeys(colonnes)\n",
    "\n",
    "    tmp_dict['date_mutation'] = [tmp_dataset.loc[index, 'date_mutation']]\n",
    "    tmp_dict['code_postal'] = [tmp_dataset.loc[index, 'code_postal']]\n",
    "    tmp_dict['code_commune'] = [tmp_dataset.loc[index, 'code_commune']]\n",
    "    tmp_dict['code_departement'] = [tmp_dataset.loc[index, 'code_departement']]\n",
    "    tmp_dict['nombre_lots'] = [tmp_dataset.loc[index, 'nombre_lots'].sum()]\n",
    "    tmp_dict['surface_reelle_bati'] = [tmp_dataset.loc[index, 'surface_reelle_bati'].sum()]\n",
    "    tmp_dict['nombre_pieces_principales'] = [tmp_dataset.loc[index, 'nombre_pieces_principales'].sum()]\n",
    "    tmp_dict['surface_terrain'] = [tmp_dataset.loc[index, 'surface_terrain'].sum()]\n",
    "    tmp_dict['valeur_fonciere'] = [tmp_dataset.loc[index, 'valeur_fonciere']]\n",
    "    tmp_dict['longitude'] = [tmp_dataset.loc[index, 'longitude']]\n",
    "    tmp_dict['latitude'] = [tmp_dataset.loc[index, 'latitude']]\n",
    "\n",
    "    # valeur classe code type local\n",
    "    tmp_code_type_local = tmp_dataset.loc[:, 'type_local']\n",
    "    for code_type in classe_liste_code_type_local:\n",
    "        tmp_dict[code_type] = [tmp_code_type_local.loc[tmp_code_type_local == code_type].size]\n",
    "\n",
    "    # valeur prefixe voie\n",
    "    tmp_abbrev_voie = tmp_dataset.loc[:, 'prefixe_voie']\n",
    "    for abbrev_voie in classe_liste_prefixe_voie:\n",
    "        tmp_dict[abbrev_voie] = [tmp_abbrev_voie.loc[tmp_abbrev_voie == abbrev_voie].size]\n",
    "\n",
    "    # valeur classe nature mutation\n",
    "    tmp_nature_mutation = tmp_dataset.loc[:, 'nature_mutation']\n",
    "    for nat_mutation in classe_liste_nature_mutation:\n",
    "        tmp_dict[nat_mutation] = [tmp_nature_mutation.loc[tmp_nature_mutation == nat_mutation].size]\n",
    "\n",
    "    # valeur classe culture\n",
    "    tmp_culture = tmp_dataset.loc[:, 'code_nature_culture']\n",
    "    for culture in classe_liste_code_culture:\n",
    "        tmp_dict[culture] = [tmp_culture.loc[tmp_culture == culture].size]\n",
    "\n",
    "    # valeur classe culture spe\n",
    "    tmp_culture_spe = tmp_dataset.loc[:, 'code_nature_culture_speciale']\n",
    "\n",
    "    for culture_spe in classe_liste_code_culture_spe:\n",
    "        tmp_dict[culture_spe] = [tmp_culture_spe.loc[tmp_culture_spe == culture_spe].size]\n",
    "\n",
    "    Data = pd.concat([Data, pd.DataFrame.from_dict(tmp_dict)], ignore_index=True, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-31T22:03:56.274574Z",
     "start_time": "2023-08-31T22:03:34.678427500Z"
    }
   },
   "id": "e980bef1632bebff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Data = pd.DataFrame()\n",
    "for i, id in enumerate(list_id_mutation):\n",
    "\n",
    "    tmp_dataset = test.loc[dataset.id_mutation == id]\n",
    "    index = tmp_dataset.index[0]\n",
    "\n",
    "    tmp_dict = dict.fromkeys(colonnes)\n",
    "\n",
    "    tmp_dict['date_mutation'] = [tmp_dataset.loc[index, 'date_mutation']]\n",
    "    tmp_dict['code_postal'] = [tmp_dataset.loc[index, 'code_postal']]\n",
    "    tmp_dict['code_commune'] = [tmp_dataset.loc[index, 'code_commune']]\n",
    "    tmp_dict['code_departement'] = [tmp_dataset.loc[index, 'code_departement']]\n",
    "    tmp_dict['nombre_lots'] = [tmp_dataset.loc[index, 'nombre_lots'].sum()]\n",
    "    tmp_dict['surface_reelle_bati'] = [tmp_dataset.loc[index, 'surface_reelle_bati'].sum()]\n",
    "    tmp_dict['nombre_pieces_principales'] = [tmp_dataset.loc[index, 'nombre_pieces_principales'].sum()]\n",
    "    tmp_dict['surface_terrain'] = [tmp_dataset.loc[index, 'surface_terrain'].sum()]\n",
    "    tmp_dict['valeur_fonciere'] = [tmp_dataset.loc[index, 'valeur_fonciere']]\n",
    "    tmp_dict['longitude'] = [tmp_dataset.loc[index, 'longitude']]\n",
    "    tmp_dict['latitude'] = [tmp_dataset.loc[index, 'latitude']]\n",
    "\n",
    "    # valeur classe code type local\n",
    "    count_type_local = Counter(tmp_dataset.loc[:, 'type_local'])\n",
    "    for type_local in count_type_local:\n",
    "        tmp_dict[type_local] = count_type_local[type_local]\n",
    "\n",
    "    # valeur prefixe voie\n",
    "    count_prefixe_voie = Counter(tmp_dataset.loc[:, 'prefixe_voie'])\n",
    "    for abbrev_voie in count_prefixe_voie:\n",
    "        tmp_dict[abbrev_voie] = count_prefixe_voie[abbrev_voie]\n",
    "\n",
    "    # valeur classe nature mutation\n",
    "    count_nature_mutation = Counter(tmp_dataset.loc[:, 'nature_mutation'])\n",
    "    for nat_mutation in count_nature_mutation:\n",
    "        tmp_dict[nat_mutation] = count_nature_mutation[nat_mutation]\n",
    "\n",
    "    # valeur classe culture\n",
    "    count_type_culture = Counter(tmp_dataset.loc[:, 'code_nature_culture'])\n",
    "    for culture in count_type_culture:\n",
    "        tmp_dict[culture] = count_type_culture[culture]\n",
    "\n",
    "    # valeur classe culture\n",
    "    count_type_culture_spe = Counter(tmp_dataset.loc[:, 'code_nature_culture_speciale'])\n",
    "    for culture_spe in count_type_culture_spe:\n",
    "        tmp_dict[culture_spe] = count_type_culture_spe[culture_spe]\n",
    "\n",
    "    Data = pd.concat([Data, pd.DataFrame.from_dict(tmp_dict)], ignore_index=True, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T22:03:35.659918500Z"
    }
   },
   "id": "b25ec9b0c30b0870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def traitement_id(id: str, dataset: DataFrame, colonnes: np.array, ) -> DataFrame:\n",
    "    tmp_dataset = dataset.loc[dataset.id_mutation == id]\n",
    "    index = tmp_dataset.index[0]\n",
    "\n",
    "    tmp_dict = dict.fromkeys(colonnes)\n",
    "\n",
    "    tmp_dict['date_mutation'] = [tmp_dataset.loc[index, 'date_mutation']]\n",
    "    tmp_dict['code_postal'] = [tmp_dataset.loc[index, 'code_postal']]\n",
    "    tmp_dict['code_commune'] = [tmp_dataset.loc[index, 'code_commune']]\n",
    "    tmp_dict['code_departement'] = [tmp_dataset.loc[index, 'code_departement']]\n",
    "    tmp_dict['nombre_lots'] = [tmp_dataset.loc[index, 'nombre_lots'].sum()]\n",
    "    tmp_dict['surface_reelle_bati'] = [tmp_dataset.loc[index, 'surface_reelle_bati'].sum()]\n",
    "    tmp_dict['nombre_pieces_principales'] = [tmp_dataset.loc[index, 'nombre_pieces_principales'].sum()]\n",
    "    tmp_dict['surface_terrain'] = [tmp_dataset.loc[index, 'surface_terrain'].sum()]\n",
    "    tmp_dict['valeur_fonciere'] = [tmp_dataset.loc[index, 'valeur_fonciere']]\n",
    "    tmp_dict['longitude'] = [tmp_dataset.loc[index, 'longitude']]\n",
    "    tmp_dict['latitude'] = [tmp_dataset.loc[index, 'latitude']]\n",
    "\n",
    "    # valeur classe code type local\n",
    "    count_type_local = Counter(tmp_dataset.loc[:, 'type_local'])\n",
    "    for type_local in count_type_local:\n",
    "        tmp_dict[type_local] = count_type_local[type_local]\n",
    "\n",
    "    # valeur prefixe voie\n",
    "    count_prefixe_voie = Counter(tmp_dataset.loc[:, 'prefixe_voie'])\n",
    "    for abbrev_voie in count_prefixe_voie:\n",
    "        tmp_dict[abbrev_voie] = count_prefixe_voie[abbrev_voie]\n",
    "\n",
    "    # valeur classe nature mutation\n",
    "    count_nature_mutation = Counter(tmp_dataset.loc[:, 'nature_mutation'])\n",
    "    for nat_mutation in count_nature_mutation:\n",
    "        tmp_dict[nat_mutation] = count_nature_mutation[nat_mutation]\n",
    "\n",
    "    # valeur classe culture\n",
    "    count_type_culture = Counter(tmp_dataset.loc[:, 'code_nature_culture'])\n",
    "    for culture in count_type_culture:\n",
    "        tmp_dict[culture] = count_type_culture[culture]\n",
    "\n",
    "    # valeur classe culture\n",
    "    count_type_culture_spe = Counter(tmp_dataset.loc[:, 'code_nature_culture_speciale'])\n",
    "    for culture_spe in count_type_culture_spe:\n",
    "        tmp_dict[culture_spe] = count_type_culture_spe[culture_spe]\n",
    "\n",
    "    return pd.DataFrame.from_dict(tmp_dict).fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T22:03:35.662911900Z"
    }
   },
   "id": "c76bc80b4cf5e2a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sortie de la colonne resultat\n",
    "\n",
    "## Y = df.valeur_fonciere"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-31T22:03:35.664915100Z"
    }
   },
   "id": "1b3922c306493006"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
